<?xml version="1.0" encoding="UTF-8"?>

<!--Autogenerated by Cloudera Manager-->
<configuration>
  <property>
    <name>dfs.namenode.hosts.provider.classname</name>
    <value>org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///disk1/data/dfs/nn,file:///disk2/data/dfs/nn,file:///disk3/data/dfs/nn,file:///disk4/data/dfs/nn,file:///disk5/data/dfs/nn,file:///disk6/data/dfs/nn</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///disk1/data/dfs/dn,file:///disk2/data/dfs/dn,file:///disk3/data/dfs/dn,file:///disk4/data/dfs/dn,file:///disk5/data/dfs/dn,file:///disk6/data/dfs/dn</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address</name>
    <value>lv111.dct-znv.com:8022</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address</name>
    <value>lv111.dct-znv.com:8020</value>
  </property>
  <property>
    <name>dfs.https.address</name>
    <value>lv111.dct-znv.com:50470</value>
  </property>
  <property>
    <name>dfs.https.port</name>
    <value>50470</value>
  </property>
  <property>
    <name>dfs.namenode.http-address</name>
    <value>lv111.dct-znv.com:50070</value>
  </property>
  <property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>lv111.dct-znv.com:50090</value>
  </property>
  <property>
    <name>dfs.namenode.secondary.https-address</name>
    <value>lv111.dct-znv.com:50495</value>
  </property>
  <property>
    <name>dfs.secondary.https.port</name>
    <value>50495</value>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>supergroup</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.namenode.replication.min</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.replication.max</name>
    <value>512</value>
  </property>
  <property>
    <name>dfs.namenode.maintenance.replication.min</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>134217728</value>
  </property>
  <property>
    <name>dfs.image.transfer.timeout</name>
    <value>60000</value>
  </property>
  <property>
    <name>dfs.image.transfer.bandwidthPerSec</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.namenode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>30</value>
  </property>
  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>30</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir.restore</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.thrift.threads.max</name>
    <value>20</value>
  </property>
  <property>
    <name>dfs.thrift.threads.min</name>
    <value>10</value>
  </property>
  <property>
    <name>dfs.thrift.timeout</name>
    <value>60</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.threshold-pct</name>
    <value>0.999</value>
  </property>
  <property>
    <name>dfs.namenode.invalidate.work.pct.per.iteration</name>
    <value>0.32</value>
  </property>
  <property>
    <name>dfs.namenode.replication.work.multiplier.per.iteration</name>
    <value>10</value>
  </property>
  <property>
    <name>dfs.namenode.replication.max-streams</name>
    <value>20</value>
  </property>
  <property>
    <name>dfs.namenode.replication.max-streams-hard-limit</name>
    <value>40</value>
  </property>
  <property>
    <name>dfs.namenode.avoid.read.stale.datanode</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.snapshot.capture.openfiles</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.avoid.write.stale.datanode</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.stale.datanode.interval</name>
    <value>30000</value>
  </property>
  <property>
    <name>dfs.namenode.write.stale.datanode.ratio</name>
    <value>0.5</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.min.datanodes</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.extension</name>
    <value>30000</value>
  </property>
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>false</value>
  </property>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>022</value>
  </property>
   <property>
    <name>dfs.namenode.checkpoint.dir</name>
    <value>file:///disk1/data/dfs/snn,file:///disk2/data/dfs/snn,file:///disk3/data/dfs/snn,file:///disk4/data/dfs/snn,file:///disk5/data/dfs/snn,file:///disk6/data/dfs/snn</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.period</name>
    <value>3600</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer.algorithm</name>
    <value>rc4</value>
  </property>
  <property>
    <name>dfs.namenode.acls.enabled</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.access.time.precision</name>
    <value>3600000</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.txns</name>
    <value>1000000</value>
  </property>
  <property>
    <name>dfs.qjournal.write-txns.timeout.ms</name>
    <value>20000</value>
  </property>
  <property>
    <name>dfs.qjournal.start-segment.timeout.ms</name>
    <value>20000</value>
  </property>
  <property>
    <name>dfs.qjournal.prepare-recovery.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.accept-recovery.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.finalize-segment.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.select-input-streams.timeout.ms</name>
    <value>20000</value>
  </property>
  <property>
    <name>dfs.qjournal.get-journal-state.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.new-epoch.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.datanode.address</name>
    <value>lv111.dct-znv.com:50010</value>
  </property>
  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>lv111.dct-znv.com:50020</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>lv111.dct-znv.com:50075</value>
  </property>
  <property>
    <name>dfs.datanode.https.address</name>
    <value>lv111.dct-znv.com:50475</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>700</value>
  </property>
  <property>
    <name>dfs.datanode.handler.count</name>
    <value>8</value>
  </property>
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value>4096</value>
  </property>
  <property>
    <name>dfs.datanode.du.reserved</name>
    <value>10737418240</value>
  </property>
  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>10485760</value>
  </property>
  <property>
    <name>dfs.datanode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hdfs-sockets/dn</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit.skip.checksum</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.domain.socket.data.traffic</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.drop.cache.behind.writes</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.drop.cache.behind.reads</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.sync.behind.writes</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.readahead.bytes</name>
    <value>4194304</value>
  </property>
  <property>
    <name>dfs.datanode.use.datanode.hostname</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
    <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy</value>
  </property>
  <property>
    <name>dfs.datanode.max.locked.memory</name>
    <value>4294967296</value>
  </property>
  <property>
    <name>DataNode failed disk tolerance</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.datanode.socket.write.timeout</name>
    <value>600000</value>
  </property>
  <property>
    <name>dfs.socket.timeout</name>
    <value>600000</value>
  </property>
</configuration>
